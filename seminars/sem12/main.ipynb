{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Марковская модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "from nltk.corpus import brown\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk.lm as lm\n",
    "from nltk.util import ngrams as nltk_ngrams\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown Dataset HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('brown')\n",
    "english = re.compile('^[a-z]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for sent in brown.sents():\n",
    "    for w in sent:\n",
    "        w = w.lower()\n",
    "        if english.match(w):\n",
    "                tokens.append(w)\n",
    "print(f'Number of tokens: {len(tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(tokens)\n",
    "len(text), text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised обучение скрытой марковской модели (Алгоритм Баума-Велша)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = hmm.HiddenMarkovModelTrainer(range(2), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = trainer.train_unsupervised([text[:5000]], max_iterations=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем полученную модель\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица переходов $$\\{a_{ij} = p(s_j|s_i)\\}_{i,j = 1}^{|S|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_matr = pd.DataFrame(data=np.array([\n",
    "    [2 ** log_p for log_p in tagger._transitions[0]._data],\n",
    "    [2 ** log_p for log_p in tagger._transitions[1]._data]\n",
    "]),\n",
    "                         columns=[0, 1],\n",
    "                         index=[0, 1])\n",
    "trans_matr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица выходных вероятностей $$\\{ b_{ij} = p(x_j|s_i) \\}_{i, j = 1}^{|S|, |X|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_matr = pd.DataFrame(data=np.array([\n",
    "    [2 ** log_p for log_p in tagger._outputs[0]._data],\n",
    "    [2 ** log_p for log_p in tagger._outputs[1]._data]\n",
    "]),\n",
    "                        index=[0, 1],\n",
    "                        columns=vocab)\n",
    "out_matr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised обучение скрытой марковской модели (максимум правдоподобия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tag(c):\n",
    "    if c in 'aeiou':\n",
    "        return (c,'1')\n",
    "    else:\n",
    "        return (c,'0')\n",
    "supervised = [make_tag(c) for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = trainer.train_supervised([supervised[:500]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем полученную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частоты совстречаемостей тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tagger._transitions:\n",
    "    print(t, tagger._transitions[t].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица переходов $$\\{a_{ij} = p(s_j|s_i)\\}_{i,j = 1}^{|S|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_matr = pd.DataFrame(data=np.array([\n",
    "    [tagger._transitions['0'].prob('0'), tagger._transitions['0'].prob('1')],\n",
    "    [tagger._transitions['1'].prob('0'), tagger._transitions['1'].prob('1')]\n",
    "]),\n",
    "                         columns=[0, 1],\n",
    "                         index=[0, 1])\n",
    "trans_matr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица выходных вероятностей $$\\{ b_{ij} = p(x_j|s_i) \\}_{i, j = 1}^{|S|, |X|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_matr = pd.DataFrame(data=np.array([\n",
    "    [tagger._outputs['0'].prob(c) for c in vocab],\n",
    "    [tagger._outputs['1'].prob(c) for c in vocab]\n",
    "]),\n",
    "                        index=[0, 1],\n",
    "                        columns=vocab)\n",
    "out_matr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Языковая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим языковую модель сначала вручную на простом синтетическом корпусе, затем обучим модель из пакета `nltk` на стихотворении \"Дом, который построил Джек\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'SOS SOS ' + 'А Б ' * 100 + 'EOS'\n",
    "tokens = text.split()\n",
    "n = len(tokens)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_and_prefix_counts(tokens, n_max):\n",
    "    # словарь n-грамм и их частот\n",
    "    ngrams_counts = {}\n",
    "    # словарь n-граммных префиксов и их частот\n",
    "    prefix_counts = {}\n",
    "    \n",
    "    n = len(tokens)\n",
    "    for i in range(n_max):\n",
    "        ngrams_counts[i + 1] = Counter([tuple(tokens[j : j + i + 1]) for j in range(n - i)])\n",
    "        prefix_counts[i + 1] = Counter([tuple(tokens[j : j + i] + ['*']) for j in range(n - i)])\n",
    "\n",
    "    return ngrams_counts, prefix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts, prefix_counts = ngrams_and_prefix_counts(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-граммы и их частотные вероятности\n",
    "\n",
    "$$\\hat p_i = \\hat p(w_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_probas(ngram_counts):\n",
    "    p1 = {}\n",
    "    n = sum(ngram_counts[1].values())\n",
    "    for w in ngram_counts[1]:\n",
    "        p1[w] = ngram_counts[1][w] / n\n",
    "    return p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = unigram_probas(ngram_counts)\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat p_{i, i - 1} = \\hat p(w_i|w_{i - 1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_probas(ngram_counts, prefix_counts):\n",
    "    p2 = {}\n",
    "    for w in ngram_counts[2]:\n",
    "        pre_w = tuple([w[0]] + ['*'])\n",
    "        p2[u'{1}|{0}'.format(*w)] = ngram_counts[2][w] / prefix_counts[2][pre_w]\n",
    "    return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = bigram_probas(ngram_counts, prefix_counts)\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat p_{i, i - 1, i - 2} = \\hat p(w_i|w_{i - 1}, w_{i - 2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_probas(ngram_counts, prefix_counts):\n",
    "    p3 = {}\n",
    "    for w in ngram_counts[3]:\n",
    "        pre_w = w[:2] + tuple(['*'])\n",
    "        p3[u'{2}|{1},{0}'.format(*w)] = ngram_counts[3][w] / prefix_counts[3][pre_w]\n",
    "    return p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 =  trigram_probas(ngram_counts, prefix_counts)\n",
    "p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка гипотезы, что триграммную модель можно свести к биграммной против правосторонней альтернативы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистика:\n",
    "$$-2 \\log (\\prod_{i, j, k = 1}^m (\\hat p_{ij} / \\hat p_{ijk})^{n_{ijk}}) = \\sum_{i, j, k}^m -2 n_{ijk} \\log \\hat p_{ij} + 2 n_{ijk} \\log \\hat p_{ijk} = \\sum_{i = 3}^N -2 \\log \\hat p_{i,i - 1} + 2 \\log \\hat p_{i, i - 1, i - 2},$$\n",
    "$$n_{ijk} = |\\{X_t: X_t = O_i, X_{t + 1} = O_j, X_{t + 2} = O_k\\}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_statistic(p2, p3, tokens):\n",
    "    stat2 = []\n",
    "    stat3 = []\n",
    "    n = len(tokens)\n",
    "    for i in range(n - 2):\n",
    "        w = tokens[i : i + 3]\n",
    "        ngram3 = '{2}|{1},{0}'.format(*w)\n",
    "        ngram2 = '{1}|{0}'.format(*w)\n",
    "\n",
    "        stat2.append(np.log(p2[ngram2]))\n",
    "        stat3.append(np.log(p3[ngram3]))\n",
    "    return - 2 * np.sum(stat2) + 2 * np.sum(stat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(p3)\n",
    "stat = chi2_statistic(p2, p3, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-value = {1 - st.distributions.chi2(m * ((m - 1) ** 2) - 1).cdf(stat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Второй пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'SOS SOS ' + 'А Б Б А Б А Б А Б Б А А ' * 100\n",
    "tokens = text.split()\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts, prefix_counts = ngrams_and_prefix_counts(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = unigram_probas(ngram_counts)\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = bigram_probas(ngram_counts, prefix_counts)\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 =  trigram_probas(ngram_counts, prefix_counts)\n",
    "p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка той же гипотезы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = chi2_statistic(p2, p3, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-value = {1 - st.distributions.chi2(m * ((m - 1) ** 2) - 1).cdf(stat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сглаживание Лапласа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = list(nltk_ngrams(tokens, 1))\n",
    "n2 = list(nltk_ngrams(tokens, 2))\n",
    "n3 = list(nltk_ngrams(tokens, 3))\n",
    "n3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = lm.Laplace(order=3)\n",
    "laplace.fit([n1] + [n2] + [n3], vocabulary_text=list(set(tokens)))\n",
    "regular_lm = lm.MLE(order=3)\n",
    "regular_lm.fit([n1] + [n2] + [n3], vocabulary_text=list(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перплексия (Меньше => лучше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.perplexity(n1), regular_lm.perplexity(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [('b'), ('a'), ('r')]\n",
    "laplace.perplexity(foo), regular_lm.perplexity(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сглаженная по Лапласу оценка вероятности\n",
    "\n",
    "$$p_L(w_i) = \\frac{c_i + 1}{\\sum_{i = 1}^v c_i + v}$$\n",
    "$$p_L(w_i|w_j) = \\frac{c_{ij} + 1}{\\sum_{j=1}^v (c_{ij} + 1)} = \\frac{c_{ij} + 1}{c_i + v}$$\n",
    "\n",
    "$$p_L('А'|'SOS')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.score('А', context=['SOS']), regular_lm.score('А', context=['SOS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p_L('SOS')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.score('SOS'), regular_lm.score('SOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-граммы не встречаючиеся в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.score('C', context=['SOS']), laplace.score('ыаываа', context=['B']), laplace.score('B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_lm.score('C', context=['SOS']), regular_lm.score('ыаываа', context=['B']), regular_lm.score('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = RegexpTokenizer(u'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/jack.txt') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = rt.tokenize(text)\n",
    "len(tokens), len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = list(nltk_ngrams(tokens, 1) )\n",
    "n2 = list(nltk_ngrams(tokens, 2))\n",
    "n3 = list(nltk_ngrams(tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = lm.Laplace(order=3)\n",
    "laplace.fit([n1] + [n2] + [n3], vocabulary_text=list(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(laplace.generate(50, random_seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(laplace.generate(50, text_seed='вот дом который построил джек'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(laplace.generate(50, text_seed='привет как дела'.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
